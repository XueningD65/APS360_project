{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APS360_project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXsnF090VQazFjxY89URF2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shirley-Dongxx/APS360_project/blob/main/APS360_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPG3l2m37qqc"
      },
      "source": [
        "# APS360 Project: Facial Age Progression and Regression\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "Contents to be added:\r\n",
        "\r\n",
        "\r\n",
        "*   Image Preprocessing\r\n",
        "*   CAAE Architecture\r\n",
        "*   GAN Architecture\r\n",
        "*   Baseline (optional)\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCtAwlUF8Nf7"
      },
      "source": [
        "## Data Preprocessing\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Dataset used: The IMDB-WIKI dataset (only the WIKI set will be used)\r\n",
        "*   Download the WIKI face only dataset at: https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\r\n",
        "\r\n",
        "\r\n",
        "**What you need to do before running the code**\r\n",
        "\r\n",
        "1.   Create a new folder called APS360_project directly under your MyDrive folder (in case you don't want to change any of the file paths in the code)\r\n",
        "2.   Upload the wiki_crop dataset to your APS360_project folder (At present I am only testing on the folder 0-9)\r\n",
        "3.   Upload the wiki.mat file to the APS360_project folder (which should have been included in your unzipped wiki_crop folder)\r\n",
        "4.   Create a new folder called wiki_processed directly under APS360_project\r\n",
        "5.   ~~Within the wiki_processed folder, create 3 folders named \"train\", \"validation\" and \"test\"~~\r\n",
        "6.   ~~Within the above 3 folders, create 2 folders named \"female\" and \"male\" (since we want to train the two genders separately)~~\r\n",
        "7.   ~~Within the gender folders, create 10 folders with folder name from 0-9~~\r\n",
        "\r\n",
        "*(have created a function to generate the folders automatically)*\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W-GV-_Y9b-R"
      },
      "source": [
        "### Import data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTzExM0E9hUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a47f224-83b2-48df-f325-d3c08a736089"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBN9Oobe2J3x"
      },
      "source": [
        "### Load the mat file of the Wiki dataset\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWcngRun4kV8"
      },
      "source": [
        "**Reference**\r\n",
        "\r\n",
        "@article\\\r\n",
        "{Rothe-IJCV-2018,\r\n",
        "  author = {Rasmus Rothe and Radu Timofte and Luc Van Gool},\\\r\n",
        "  title = {Deep expectation of real and apparent age from a single \r\n",
        "  image without facial landmarks},\\\r\n",
        "  journal = {International Journal of Computer Vision},\\\r\n",
        "  volume={126},\\\r\n",
        "  number={2-4},\\\r\n",
        "  pages={144--157},\\\r\n",
        "  year={2018},\\\r\n",
        "  publisher={Springer}\r\n",
        "}\r\n",
        "\r\n",
        "@InProceedings\\\r\n",
        "{Rothe-ICCVW-2015,\\\r\n",
        "  author = {Rasmus Rothe and Radu Timofte and Luc Van Gool},\\\r\n",
        "  title = {DEX: Deep EXpectation of apparent age from a single image},\\\r\n",
        "  booktitle = {IEEE International Conference on Computer Vision Workshops (ICCVW)},\\\r\n",
        "  year = {2015}, \\\r\n",
        "  month = {December},\\\r\n",
        "}\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqt0uJCm2PVf"
      },
      "source": [
        "from datetime import datetime, timedelta\r\n",
        "from scipy.io import loadmat\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import scipy\r\n",
        "import os\r\n",
        "import imghdr\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import itertools\r\n",
        "\r\n",
        "from collections import defaultdict\r\n",
        "from pprint import pprint\r\n",
        "from shutil import copy2\r\n",
        "\r\n",
        "import cv2\r\n",
        "import sys\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY9MCbLK2scT"
      },
      "source": [
        "# convert the matlab styled date to number\r\n",
        "def matlab_datenum_to_dt(matlab_datenum):\r\n",
        "    return datetime.fromordinal(int(matlab_datenum) - 366) + timedelta(days=int(matlab_datenum % 1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiPDfxCD3aKF",
        "outputId": "d307665a-7f00-4677-bb36-7c8f2a2d2fb9"
      },
      "source": [
        "# load wiki metadata\r\n",
        "# Modified from https://gist.github.com/messefor/e2ee5fe1c18a040c90bbf91f2ee279e3\r\n",
        "\r\n",
        "def load_wiki_meta():\r\n",
        "\r\n",
        "    # Please change to your own path when testing!\r\n",
        "    file_path = \"/content/gdrive/MyDrive/APS360_project/wiki.mat\"\r\n",
        "    save_path = \"/content/gdrive/MyDrive/APS360_project/wiki.pkl\"\r\n",
        "\r\n",
        "    mat = loadmat(file_path)\r\n",
        "\r\n",
        "    print(\"Data header:\",mat['__header__'])\r\n",
        "    print(\"Data Version:\",mat['__version__'])\r\n",
        "\r\n",
        "    # Extract values\r\n",
        "    data = mat['wiki'][0, 0]\r\n",
        "    print(\"Column names are: \", data.dtype.names)\r\n",
        "\r\n",
        "    # Data loaded in simple form\r\n",
        "    col_keys = ('dob', 'photo_taken', 'gender', 'face_location', 'face_score', 'second_face_score')\r\n",
        "    col_values = {k: data[k].squeeze() for k in col_keys}\r\n",
        "\r\n",
        "    # Data loaded into numpy arrays\r\n",
        "    col_keys_nested = ('full_path', 'name')\r\n",
        "    for key in col_keys_nested:\r\n",
        "        col_values[key] = np.array([x if not x else x[0] for x in data[key][0]])\r\n",
        "    #print(col_values['name'][5])\r\n",
        "\r\n",
        "    # Convert face location to DataFrame\r\n",
        "    # Inputs:\r\n",
        "    #    img - image (i.e. load with imread)\r\n",
        "    #    box - location of face (i.e. img(box(2):box(4),box(1):box(3),:))\r\n",
        "    #    crop_margin - margin around face as a fraction of the width, height\r\n",
        "    #    [left above right below], default is [0.4 0.4 0.4 0.4]\r\n",
        "    col_values['face_location'] =[tuple(x[0].tolist()) for x in data['face_location'].squeeze()]\r\n",
        "\r\n",
        "    # Check all values extracted have same length\r\n",
        "    set_nrows = {len(v) for _, v in col_values.items()}\r\n",
        "    assert len(set_nrows) == 1\r\n",
        "\r\n",
        "    # convert to panda data frame\r\n",
        "    df_values = pd.DataFrame(col_values)\r\n",
        "\r\n",
        "    # Convert matlab datenum to datetime\r\n",
        "    df_values['dob'] = df_values['dob'].apply(matlab_datenum_to_dt)\r\n",
        "\r\n",
        "    # Calculate ages when photo was taken\r\n",
        "    df_values['photo_taken_age'] = df_values.apply(lambda x: x['photo_taken'] - x['dob'].year, axis=1)\r\n",
        "\r\n",
        "    # Concat all together and save\r\n",
        "    # Do not use csv format to work around tuple to be string\r\n",
        "    df_values.to_pickle(save_path)\r\n",
        "\r\n",
        "load_wiki_meta()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data header: b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sat Jan 16 16:25:20 2016'\n",
            "Data Version: 1.0\n",
            "Column names are:  ('dob', 'photo_taken', 'full_path', 'gender', 'name', 'face_location', 'face_score', 'second_face_score')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_weyT_OAgqY"
      },
      "source": [
        "# check if the image is in the correct format\r\n",
        "DATA_PATH_FILTERED = \"/content/gdrive/MyDrive/APS360_project/00\"\r\n",
        "def check_path():\r\n",
        "  count = 0\r\n",
        "  for root, dirs, files in os.walk(DATA_PATH_FILTERED, topdown = False):\r\n",
        "    for name in files:\r\n",
        "      print(\"loading...\")\r\n",
        "      filepath = os.path.join(root, name)\r\n",
        "      count += 1\r\n",
        "      if imghdr.what(filepath) is not 'jpeg':\r\n",
        "        print(filepath)\r\n",
        "  print(count)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2pN95DR9o4T"
      },
      "source": [
        "### Load the image into different datasets with labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTsqe0T9AoiO"
      },
      "source": [
        "**The separation of image labels**\r\n",
        "\r\n",
        "The image labels are separated based on the age of the person when the photo was taken.\r\n",
        "\r\n",
        "Label  | Age Range (Inclusive)\r\n",
        "-------------------|------------------\r\n",
        "0      | 0-5\r\n",
        "1     | 6-10\r\n",
        "2      | 11-15\r\n",
        "3    | 16-20 \r\n",
        "4      | 21-30\r\n",
        "5     | 31-40 \r\n",
        "6      | 41-50\r\n",
        "7     | 51-60\r\n",
        "8      | 61-70\r\n",
        "9     | 71+ \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efpqZMpo7p85"
      },
      "source": [
        "# record the paths of data and metadata\r\n",
        "# please change to your own path when running\r\n",
        "META_PATH = \"/content/gdrive/MyDrive/APS360_project/wiki.pkl\"\r\n",
        "\r\n",
        "\r\n",
        "IMG_SIZE = 2048\r\n",
        "\r\n",
        "# count the number of faces in the image\r\n",
        "def count_face(imagePath):\r\n",
        "\r\n",
        "  image = cv2.imread(imagePath)\r\n",
        "  #cv2_imshow(image)\r\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "  faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\r\n",
        "  faces = faceCascade.detectMultiScale(\r\n",
        "      gray,\r\n",
        "      scaleFactor=1.3,\r\n",
        "      minNeighbors=3,\r\n",
        "      minSize=(30, 30)\r\n",
        "  )\r\n",
        "\r\n",
        "  print(\"[INFO] Found {0} Faces.\".format(len(faces)))\r\n",
        "  return len(faces)\r\n",
        "\r\n",
        "# get the gender of the image\r\n",
        "def get_gender(gender):\r\n",
        "    if(gender == 1.0):\r\n",
        "      return \"male\"\r\n",
        "    else:\r\n",
        "      return \"female\"\r\n",
        "\r\n",
        "# check if the image is valid\r\n",
        "def check_valid_image(path):\r\n",
        "    # if no image can be retrieved from the path\r\n",
        "    if not (os.path.isfile(path)):\r\n",
        "      print(\"Invalid Path!\")\r\n",
        "      return False\r\n",
        "\r\n",
        "    # if the size of the image is too large\r\n",
        "    if not (os.path.getsize(path) > IMG_SIZE):\r\n",
        "      print(\"Invalid Size!\")\r\n",
        "      return False\r\n",
        "    \r\n",
        "    # if there are no faces or too many faces\r\n",
        "    if (count_face(path)!=1):\r\n",
        "      print(\"Abort picture!\")\r\n",
        "      return False\r\n",
        "\r\n",
        "    return True\r\n",
        "\r\n",
        "# check if the age of the person is in our range\r\n",
        "def check_valid_age(age):\r\n",
        "    if (age < 0 or age > 100):\r\n",
        "      return False\r\n",
        "    return True"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB98MPzEB4dE"
      },
      "source": [
        "def get_age_label(age):\r\n",
        "    if 0 <= age <= 5:\r\n",
        "        label = 0\r\n",
        "    elif 6 <= age <= 10:\r\n",
        "        label = 1\r\n",
        "    elif 11 <= age <= 15:\r\n",
        "        label = 2\r\n",
        "    elif 16 <= age <= 20:\r\n",
        "        label = 3\r\n",
        "    elif 21 <= age <= 30:\r\n",
        "        label = 4\r\n",
        "    elif 31 <= age <= 40:\r\n",
        "        label = 5\r\n",
        "    elif 41 <= age <= 50:\r\n",
        "        label = 6\r\n",
        "    elif 51 <= age <= 60:\r\n",
        "        label = 7\r\n",
        "    elif 61 <= age <= 70:\r\n",
        "        label = 8\r\n",
        "    else:\r\n",
        "        label = 9\r\n",
        "\r\n",
        "    return label"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-unV5CIaNDR7"
      },
      "source": [
        "def getBaseFilename(filename):\r\n",
        "    return filename.split('/')[-1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcMCPKazQDQz"
      },
      "source": [
        "def get_folder(filename):\r\n",
        "    return int(filename.split('/')[0])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wFn2SLzWzkW"
      },
      "source": [
        "def print_age_distribution(age_count):\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = fig.add_axes([0,0,1,1])\r\n",
        "  age_label = [0,1,2,3,4,5,6,7,8,9]\r\n",
        "  count_label = age_count\r\n",
        "  ax.plot(age_label,count_label)\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "def print_gender_distribution(gender_count):\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = fig.add_axes([0,0,1,1])\r\n",
        "  gender_label = [\"female\", \"male\"]\r\n",
        "  count_label = gender_count\r\n",
        "  ax.bar(gender_label,count_label)\r\n",
        "  plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxXH8eC09Taz"
      },
      "source": [
        "DATA_PATH = \"/content/gdrive/MyDrive/APS360_project/wiki_crop\"\r\n",
        "DATA_SAVE_PATH = \"/content/gdrive/MyDrive/APS360_project/wiki_processed\"\r\n",
        "\r\n",
        "def process_wiki_image(file_test = False):\r\n",
        "    uploaded_folder = 19\r\n",
        "\r\n",
        "    # create the file paths\r\n",
        "    if not os.path.isdir(DATA_SAVE_PATH):\r\n",
        "        print(\"Path \", DATA_SAVE_PATH, \"has not formed\")\r\n",
        "        os.mkdir(DATA_SAVE_PATH)\r\n",
        "\r\n",
        "    if not os.path.isdir(DATA_SAVE_PATH+\"/test\"):\r\n",
        "        print(\"Path \", DATA_SAVE_PATH+\"/test\", \"has not formed\")\r\n",
        "        os.mkdir(DATA_SAVE_PATH+\"/test\")\r\n",
        "\r\n",
        "    if not os.path.isdir(DATA_SAVE_PATH+\"/train\"):\r\n",
        "        print(\"Path \", DATA_SAVE_PATH+\"/train\", \"has not formed\")\r\n",
        "        os.mkdir(DATA_SAVE_PATH+\"/train\")\r\n",
        "\r\n",
        "    if not os.path.isdir(DATA_SAVE_PATH+\"/validation\"):\r\n",
        "        print(\"Path \", DATA_SAVE_PATH+\"/validation\", \"has not formed\")\r\n",
        "        os.mkdir(DATA_SAVE_PATH+\"/validation\")\r\n",
        "\r\n",
        "    for k in range(10):\r\n",
        "        if not os.path.isdir(DATA_SAVE_PATH+\"/test/female/\"+str(k)):\r\n",
        "          print(\"Path \", DATA_SAVE_PATH+\"/test/female/\"+str(k), \"has not formed\")\r\n",
        "          os.mkdir(DATA_SAVE_PATH+\"/test/\"+str(k))\r\n",
        "\r\n",
        "        if not os.path.isdir(DATA_SAVE_PATH+\"/train/female/\"+str(k)):\r\n",
        "          print(\"Path \", DATA_SAVE_PATH+\"/train/female/\"+str(k), \"has not formed\")\r\n",
        "          os.mkdir(DATA_SAVE_PATH+\"/train/female/\"+str(k))\r\n",
        "\r\n",
        "        if not os.path.isdir(DATA_SAVE_PATH+\"/validation/female/\"+str(k)):\r\n",
        "          print(\"Path \", DATA_SAVE_PATH+\"/validation/\"+str(k), \"has not formed\")\r\n",
        "          os.mkdir(DATA_SAVE_PATH+\"/validation/female/\"+str(k))\r\n",
        "\r\n",
        "        if not os.path.isdir(DATA_SAVE_PATH+\"/test/male/\"+str(k)):\r\n",
        "          print(\"Path \", DATA_SAVE_PATH+\"/test/male/\"+str(k), \"has not formed\")\r\n",
        "          os.mkdir(DATA_SAVE_PATH+\"/test/male/\"+str(k))\r\n",
        "\r\n",
        "        if not os.path.isdir(DATA_SAVE_PATH+\"/train/male/\"+str(k)):\r\n",
        "          print(\"Path \", DATA_SAVE_PATH+\"/train/male/\"+str(k), \"has not formed\")\r\n",
        "          os.mkdir(DATA_SAVE_PATH+\"/train/male/\"+str(k))\r\n",
        "\r\n",
        "        if not os.path.isdir(DATA_SAVE_PATH+\"/validation/male/\"+str(k)):\r\n",
        "          print(\"Path \", DATA_SAVE_PATH+\"/validation/male/\"+str(k), \"has not formed\")\r\n",
        "          os.mkdir(DATA_SAVE_PATH+\"/validation/male/\"+str(k))\r\n",
        "\r\n",
        "    test_age_count,train_age_count,val_age_count = [0,0,0,0,0,0,0,0,0,0]\r\n",
        "    test_gender_count,train_gender_count,val_gender_count = [0,0]\r\n",
        "    meta = pd.read_pickle(META_PATH)\r\n",
        "\r\n",
        "    # Limit the age of the dataset set\r\n",
        "    meta = meta[meta['photo_taken_age'] >= 0]\r\n",
        "    meta = meta[meta['photo_taken_age'] <= 101]\r\n",
        "\r\n",
        "    # Converting into numpy array\r\n",
        "    meta = meta.values\r\n",
        "    remove_indices = []\r\n",
        "    for i in range(len(meta)):\r\n",
        "        if get_folder(meta[i][6])>uploaded_folder:\r\n",
        "            remove_indices.append(i)\r\n",
        "\r\n",
        "    meta = np.array(list(itertools.compress(meta, [i not in remove_indices for i in range(len(meta))])))\r\n",
        "    print(meta[0])\r\n",
        "\r\n",
        "    # Split dataset into training validation and testing set\r\n",
        "    D_train, D_test = train_test_split(meta, test_size=0.15, random_state=62)\r\n",
        "    D_train, D_val = train_test_split(D_train, test_size=0.15, random_state=51)\r\n",
        "\r\n",
        "    # Load the training set\r\n",
        "    # test a few images at first\r\n",
        "    n = 0\r\n",
        "    for i in range(len(D_train)):\r\n",
        "      age = D_train[i][-1]\r\n",
        "      #print(\"Age is\", age)\r\n",
        "\r\n",
        "      full_path = os.path.join(DATA_PATH, D_train[i][6])\r\n",
        "      #print(\"The path is:\", full_path)\r\n",
        "\r\n",
        "      # currently only testing on folder 0-9\r\n",
        "      #print(\"folder is: \",get_folder(D_train[i][6]))\r\n",
        "\r\n",
        "      if get_folder(D_train[i][6])>uploaded_folder:\r\n",
        "        #print(\"out\")\r\n",
        "        new_age = None\r\n",
        "        continue\r\n",
        "\r\n",
        "      if not check_valid_image(full_path):\r\n",
        "        continue\r\n",
        "\r\n",
        "      n += 1\r\n",
        "      print(\"n=\",n)\r\n",
        "\r\n",
        "      if file_test and n>5:\r\n",
        "        print(\"Testing end...\")\r\n",
        "        print_age_distribution(age_count)\r\n",
        "        print_gender_distribution(gender_count)\r\n",
        "        return\r\n",
        "\r\n",
        "      # obtain the gender and age of the person in the image\r\n",
        "      gender = get_gender(D_train[i][2])\r\n",
        "      age_label = get_age_label(age)\r\n",
        "      train_age_count[age_label] += 1\r\n",
        "      age_label = str(age_label)\r\n",
        "      train_gender_count[int(D_train[i][2])] += 1\r\n",
        "\r\n",
        "      new_file_path = DATA_SAVE_PATH + \"/train/\"+ gender + \"/\" + age_label +\"/\"\r\n",
        "      #print(\"The new file path is:\", new_file_path)\r\n",
        "\r\n",
        "      # check if the folder exists\r\n",
        "      if not os.path.isdir(new_file_path):\r\n",
        "        print(\"Folder not found!\")\r\n",
        "\r\n",
        "      new_file_path = os.path.join(new_file_path, getBaseFilename(D_train[i][6]))\r\n",
        "      if(file_test): \r\n",
        "        print(\"Now, the new file path is:\", new_file_path)\r\n",
        "\r\n",
        "      copy2(full_path, new_file_path)\r\n",
        "      if(file_test):\r\n",
        "        print(\"copy finished\")\r\n",
        "\r\n",
        "    for i in range(len(D_val)):\r\n",
        "      age = D_val[i][-1]\r\n",
        "      full_path = os.path.join(DATA_PATH, D_val[i][6])\r\n",
        "\r\n",
        "      if get_folder(D_val[i][6])>uploaded_folder:\r\n",
        "        new_age = None\r\n",
        "        continue\r\n",
        "\r\n",
        "      if not check_valid_image(full_path):\r\n",
        "        continue\r\n",
        "\r\n",
        "      # obtain the gender and age of the person in the image\r\n",
        "      gender = get_gender(D_val[i][2])\r\n",
        "      val_age_label = get_age_label(age)\r\n",
        "      age_count[age_label] += 1\r\n",
        "      age_label = str(age_label)\r\n",
        "      val_gender_count[int(D_val[i][2])] += 1\r\n",
        "\r\n",
        "      new_file_path = DATA_SAVE_PATH + \"/validation/\"+ gender + \"/\" + age_label +\"/\"\r\n",
        "      #print(\"The new file path is:\", new_file_path)\r\n",
        "\r\n",
        "      # check if the folder exists\r\n",
        "      if not os.path.isdir(new_file_path):\r\n",
        "        print(\"Folder not found!\")\r\n",
        "\r\n",
        "      new_file_path = os.path.join(new_file_path, getBaseFilename(D_val[i][6]))\r\n",
        "      if(file_test): \r\n",
        "        print(\"Now, the new file path is:\", new_file_path)\r\n",
        "\r\n",
        "      copy2(full_path, new_file_path)\r\n",
        "      if(file_test):\r\n",
        "        print(\"copy finished\")\r\n",
        "\r\n",
        "    # load testing data\r\n",
        "    for i in range(len(D_test)):\r\n",
        "      age = D_test[i][-1]\r\n",
        "      full_path = os.path.join(DATA_PATH, D_test[i][6])\r\n",
        "\r\n",
        "      if get_folder(D_test[i][6])>uploaded_folder:\r\n",
        "        new_age = None\r\n",
        "        continue\r\n",
        "\r\n",
        "      if not check_valid_image(full_path):\r\n",
        "        continue\r\n",
        "\r\n",
        "      # obtain the gender and age of the person in the image\r\n",
        "      gender = get_gender(D_test[i][2])\r\n",
        "      test_age_label = get_age_label(age)\r\n",
        "      age_count[age_label] += 1\r\n",
        "      age_label = str(age_label)\r\n",
        "      test_gender_count[int(D_test[i][2])] += 1\r\n",
        "\r\n",
        "      new_file_path = DATA_SAVE_PATH + \"/test/\"+ gender + \"/\" + age_label +\"/\"\r\n",
        "      #print(\"The new file path is:\", new_file_path)\r\n",
        "\r\n",
        "      # check if the folder exists\r\n",
        "      if not os.path.isdir(new_file_path):\r\n",
        "        print(\"Folder not found!\")\r\n",
        "\r\n",
        "      new_file_path = os.path.join(new_file_path, getBaseFilename(D_test[i][6]))\r\n",
        "      if(file_test): \r\n",
        "        print(\"Now, the new file path is:\", new_file_path)\r\n",
        "\r\n",
        "      copy2(full_path, new_file_path)\r\n",
        "      if(file_test):\r\n",
        "        print(\"copy finished\")\r\n",
        "\r\n",
        "    print(\"training statistics:\")\r\n",
        "    print_age_distribution(train_age_count)\r\n",
        "    print_gender_distribution(train_gender_count)\r\n",
        "\r\n",
        "    print(\"validation statistics:\")\r\n",
        "    print_age_distribution(val_age_count)\r\n",
        "    print_gender_distribution(val_gender_count)\r\n",
        "\r\n",
        "    print(\"testing statistics:\")\r\n",
        "    print_age_distribution(test_age_count)\r\n",
        "    print_gender_distribution(test_gender_count)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj3xsChmPjK_"
      },
      "source": [
        "# for testing purpose only\r\n",
        "process_wiki_image(file_test = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7j4wAvEUanP",
        "outputId": "6e5aa2fa-ddf3-4a36-b8a1-1ed932818196"
      },
      "source": [
        "'''\r\n",
        "meta = pd.read_pickle(META_PATH)\r\n",
        "import itertools\r\n",
        "\r\n",
        "# Limit the folder of the dataset set\r\n",
        "#print(meta['full_path'])\r\n",
        "#\r\n",
        "\r\n",
        "# Limit the age of the dataset set\r\n",
        "meta = meta[meta['photo_taken_age'] >= 0]\r\n",
        "meta = meta[meta['photo_taken_age'] <= 101]\r\n",
        "\r\n",
        "# Converting into numpy array\r\n",
        "meta = meta.values\r\n",
        "\r\n",
        "remove_indices = []\r\n",
        "for i in range(len(meta)):\r\n",
        "  if get_folder(meta[i][6])>19:\r\n",
        "    remove_indices.append(i)\r\n",
        "\r\n",
        "\r\n",
        "##elements_to_remove = meta[remove_indices]\r\n",
        "#meta = np.delete(meta, np.where(meta == value_to_delete))\r\n",
        "meta = np.array(list(itertools.compress(meta, [i not in remove_indices for i in range(len(meta))])))\r\n",
        "print(meta[0])\r\n",
        "print(len(meta))\r\n",
        "#\r\n",
        "# Split dataset into training validation and testing set\r\n",
        "D_train, D_test = train_test_split(meta, test_size=0.15, random_state=62)\r\n",
        "D_train, D_val = train_test_split(D_train, test_size=0.15, random_state=51)\r\n",
        "\r\n",
        "\r\n",
        "print(len(D_train))\r\n",
        "print(len(D_val))\r\n",
        "print(len(D_test))\r\n",
        "'''"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[datetime.datetime(1981, 5, 5, 0, 0) 2009 1.0\n",
            " (111.29109473290997, 111.29109473290997, 252.66993081807996, 252.66993081807996)\n",
            " 4.3009623883308095 nan '17/10000217_1981-05-05_2009.jpg'\n",
            " 'Sami Jauhoj√§rvi' 28]\n",
            "12398\n",
            "8957\n",
            "1581\n",
            "1860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o9_EJ54RS8b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxOu93D4RSS2"
      },
      "source": [
        "**What should have been obtained after data preprocessing**\r\n",
        "\r\n",
        "There will be a series of folders created in your Google Drive for storing the categorized dataset. For each train/test/validation dataset, there should be data categorized into genders and age stamps as listed above. \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56EJL4mG-daI"
      },
      "source": [
        "## Architecture I: CAAE\r\n",
        "\r\n",
        "---\r\n",
        "For both the encoder and generator, there is a four convolution layer structure with the pooling replaced by stridden convolutions. The model also consists of two discriminators, each work on the personal features (z) and the original/generated face images, assisting the generation of more realistic images.\r\n",
        "\r\n",
        "* Encoder\r\n",
        "* Generator\r\n",
        "* Discriminator-z\r\n",
        "* Discriminator - image\r\n",
        "* Others (training, data loading etc.)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPrMn1VLAS8e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfL4if3wAH2B"
      },
      "source": [
        "## Architecture II: GAN\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "Generative Adversarial Networks (GANs) use an idea of adversarial loss to force the generated image to be realistic. The network contains one generator and one discriminator. The generator is made up of convolution layers mapping the sampled noise vector to synthesized images. The discriminator takes in the real or generated face image and tries to tell them apart. The LeakyReLU activation is used in all layers in the discriminator for stabilization.\r\n",
        "\r\n",
        "\r\n",
        "* Generator\r\n",
        "* Discriminator\r\n",
        "* Others (training, data loading etc.)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDP_UnNbAUDZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}